Dockerfiles and compose scripts for running Llama.cpp server on CPU, Nvidia, or Rocm
